{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ae48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision.transforms import Compose\n",
    "from src.harmonization.inet_pn1 import IntensityNet\n",
    "from src.datasets.tools.lidar_dataset import LidarDatasetNP, LidarDatasetHDF5\n",
    "from src.datasets.tools.transforms import CloudAngleNormalize\n",
    "from src.datasets.tools.transforms import Corruption, GlobalShift, CloudJitter\n",
    "from src.datasets.dublin.config import config as dataset_config\n",
    "from src.training.config import config as train_config\n",
    "from src.datasets.tools.dataloaders import get_transforms\n",
    "\n",
    "config = {\n",
    "    'dataset': dataset_config,\n",
    "    'train': train_config\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path(f\"{config['train']['results_path']}{config['dataset']['use_ss_str']}{config['dataset']['shift_str']}\")\n",
    "n_size = config['train']['neighborhood_size']\n",
    "epoch=\"14\"\n",
    "\n",
    "device = config['train']['device']\n",
    "model = IntensityNet(\n",
    "    n_size, \n",
    "    interpolation_method=\"pointnet\").double().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(results_path / f\"{n_size}_epoch={epoch}.pt\"))\n",
    "model_path = results_path / f\"{n_size}_epoch={epoch}.pt\"\n",
    "print(f\"Loaded model: {model_path}\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the eval tile if it doesn't exist\n",
    "from src.datasets.tools.create_dataset import create_eval_tile, setup_eval_hdf5\n",
    "if config['dataset']['eval_dataset'].exists():\n",
    "    config['dataset']['eval_dataset'].unlink()\n",
    "setup_eval_hdf5(config['dataset'])\n",
    "\n",
    "# seems like this works faster when you write chunks that are smaller than the max chunk size set during dataset creation\n",
    "# create_eval_tile(config['dataset'], chunk_size=config['dataset']['max_chunk_size'])\n",
    "create_eval_tile(config['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the eval tile\n",
    "transforms = get_transforms(config)\n",
    "print(transforms)\n",
    "eval_tile = config['dataset']['eval_dataset']\n",
    "eval_source = config['dataset']['eval_source_scan']\n",
    "lidar_dataset = LidarDatasetHDF5(\n",
    "                Path(config['dataset']['eval_dataset']), \n",
    "                transform=transforms,\n",
    "                mode='eval',\n",
    "                ss=config['dataset']['use_ss'])\n",
    "eval_dataloader = DataLoader(\n",
    "            lidar_dataset,\n",
    "            batch_size=config['train']['batch_size'],\n",
    "            sampler=None,\n",
    "            shuffle=False,\n",
    "            num_workers=config['train']['num_workers'],\n",
    "            drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591dd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_scan_num = 1\n",
    "size = config['dataset']['eval_tile_size']\n",
    "hz = torch.empty(size).double()\n",
    "ip = torch.empty(size).double()\n",
    "cr = torch.empty(size).double()\n",
    "gt = torch.empty(size).double()\n",
    "xyz = torch.empty(size, 3).double()\n",
    "\n",
    "n_size = config['train']['neighborhood_size']\n",
    "b_size = config['train']['batch_size']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(eval_dataloader):\n",
    "        ldx = i * b_size\n",
    "        hdx = (i+1) * b_size\n",
    "        xyz[ldx:hdx] = batch[:, 0, :3]\n",
    "        batch[:, 0, -1] = target_scan_num\n",
    "        \n",
    "        batch = batch.to(config['train']['device'])\n",
    "        \n",
    "        h_target = batch[:, 0, 3].clone()\n",
    "        i_target = batch[:, 1, 3].clone()\n",
    "        harmonization, interpolation, _ = model(batch)\n",
    "        \n",
    "        \n",
    "        hz[ldx:hdx] = harmonization.cpu().squeeze()\n",
    "        ip[ldx:hdx] = interpolation.cpu().squeeze()\n",
    "        cr[ldx:hdx] = i_target.cpu() # corruption\n",
    "        gt[ldx:hdx] = h_target.cpu()\n",
    "        \n",
    "scan_error = torch.mean(torch.abs((gt - hz)))\n",
    "corruption_error = torch.mean(torch.abs((cr - gt)))\n",
    "interpolation_error = torch.mean(torch.abs((ip - cr)))\n",
    "\n",
    "print(f\"Results: Harmonization MAE: {scan_error}, Corruption MAE: {corruption_error}, Interpolation MAE: {interpolation_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.tools.metrics import create_kde\n",
    "create_kde(gt, np.clip(hz.numpy(), 0, 1), xlabel=\"gt\", ylabel=\"predicted harmonization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hz.shape, cr.shape, ip.shape, gt.shape, xyz.shape)\n",
    "my_cloud = np.concatenate((xyz.numpy(), \n",
    "                           np.expand_dims(gt.numpy(), 1),\n",
    "                           np.expand_dims(np.clip(hz.numpy(), 0, 1), 1),\n",
    "                           np.expand_dims(cr.numpy(), 1),\n",
    "                           np.expand_dims(np.clip(ip.numpy(), 0, 1), 1)\n",
    "                          ), axis=1)\n",
    "                           \n",
    "print(my_cloud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f608ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptk import viewer\n",
    "v = viewer(my_cloud[:, :3])\n",
    "#       gt,             hz,             cr,             ip\n",
    "attr = [my_cloud[:, 3], my_cloud[:, 4], my_cloud[:, 5], my_cloud[:, 6]]\n",
    "v.attributes(*attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e24b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.set(r=245.5078125, theta=1.57079637, phi=-1.57079637, lookat=config['dataset']['eval_tile_center'])\n",
    "v.set(show_grid=False, show_info=False, show_axis=False, bg_color=[1, 1, 1, 1])\n",
    "v.color_map(\"jet\", scale=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a20f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "v.set(curr_attribute_id=0); time.sleep(.5)\n",
    "v.capture(\"et_gt.png\")\n",
    "v.set(curr_attribute_id=3); time.sleep(.5)\n",
    "v.capture(\"et_ip.png\")\n",
    "v.set(curr_attribute_id=1); time.sleep(.5)\n",
    "v.capture(\"et_hz.png\")\n",
    "v.set(curr_attribute_id=2); time.sleep(.5)\n",
    "v.capture(\"et_cr.png\")\n",
    "time.sleep(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7244c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "figname = f\"igarss_fig{config['dataset']['shift_str']}.png\"\n",
    "images = [Image.open(x) for x in ['et_gt.png', 'et_hz.png', 'et_cr.png']]\n",
    "widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "total_width = sum(widths)\n",
    "max_height = max(heights)\n",
    "\n",
    "new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "x_offset = 0\n",
    "for im in images:\n",
    "    new_im.paste(im, (x_offset,0))\n",
    "    x_offset += im.size[0]\n",
    "\n",
    "new_im.save(figname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb31c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IpImage\n",
    "IpImage(filename=figname) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f83577",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff754140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform histogram matching on this tile!\n",
    "# we can re-use my_cloud with the CR channel and then just apply histogram using\n",
    "# whatever target scan was originally chosen\n",
    "\n",
    "from src.evaluation.histogram_matching import hist_match\n",
    "\n",
    "corrupted_intensities = my_cloud[:, 5].copy()\n",
    "target_cloud = np.load(config['dataset']['scans_path'] / (config['dataset']['target_scan']+'.npy'))\n",
    "print(target_cloud.shape)\n",
    "harmonized_intensities = hist_match(corrupted_intensities, target_cloud[:, 3])\n",
    "print(harmonized_intensities.shape)\n",
    "\n",
    "v = viewer(my_cloud[:, :3])\n",
    "#       gt,             hz,                     cr             \n",
    "attr = [my_cloud[:, 3], harmonized_intensities, my_cloud[:, 5]]\n",
    "v.attributes(*attr)\n",
    "\n",
    "v.set(r=245.5078125, theta=1.57079637, phi=-1.57079637, lookat=config['dataset']['eval_tile_center'])\n",
    "v.set(show_grid=False, show_info=False, show_axis=False, bg_color=[1, 1, 1, 1])\n",
    "v.color_map(\"jet\", scale=[0, 1])\n",
    "\n",
    "v.set(curr_attribute_id=0); time.sleep(.5)\n",
    "v.capture(\"et_gt.png\")\n",
    "v.set(curr_attribute_id=1); time.sleep(.5)\n",
    "v.capture(\"et_hz.png\")\n",
    "v.set(curr_attribute_id=2); time.sleep(.5)\n",
    "v.capture(\"et_cr.png\")\n",
    "time.sleep(.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969bddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "figname = f\"igarss_fig{config['dataset']['shift_str']}_hm.png\"\n",
    "images = [Image.open(x) for x in ['et_gt.png', 'et_hz.png', 'et_cr.png']]\n",
    "widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "total_width = sum(widths)\n",
    "max_height = max(heights)\n",
    "\n",
    "new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "x_offset = 0\n",
    "for im in images:\n",
    "    new_im.paste(im, (x_offset,0))\n",
    "    x_offset += im.size[0]\n",
    "new_im = new_im.convert(\"RGBA\")\n",
    "new_im.save(figname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IpImage(filename=figname) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.tools.metrics import create_kde\n",
    "create_kde(gt, harmonized_intensities, xlabel=\"gt\", ylabel=\"predicted harmonization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a6cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_error = np.mean(np.abs(gt.numpy() - harmonized_intensities))\n",
    "print(scan_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d59fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Path(img).unlink() for img in ['et_gt.png', 'et_hz.png', 'et_cr.png', 'et_ip.png']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b947abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
